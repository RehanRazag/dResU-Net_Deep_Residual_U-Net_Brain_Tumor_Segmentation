# -*- coding: utf-8 -*-
"""3D__dResu_Net_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q4w0CRELv6T1n0L5nuLDebrqnTeqWFDq

# **Model - 3D Deep Residual U-Net**

## **Essential required Libraries**
"""

import os
import numpy as np
import tensorflow as tf
import keras
from matplotlib import pyplot as plt
import glob
import random
from tensorflow.keras import models, layers, regularizers

from keras.models import Model
from keras.layers import Input, Conv3D, MaxPooling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda
from tensorflow.keras.optimizers import Adam
from keras.metrics import MeanIoU
from tensorflow.keras.callbacks import ModelCheckpoint
import tensorflow.keras.backend as K
from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum

"""## **Custom Data Generator for Loading .npy Files**"""

import os
import numpy as np

def load_img(img_dir, img_list):
    images=[]
    for i, image_name in enumerate(img_list):
        if (image_name.split('.')[1] == 'npy'):

            image = np.load(img_dir+image_name)

            images.append(image)
    images = np.array(images)

    return(images)

def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):

    L = len(img_list)

    #keras needs the generator infinite, so we will use while true
    while True:

        batch_start = 0
        batch_end = batch_size

        while batch_start < L:
            limit = min(batch_end, L)

            X = load_img(img_dir, img_list[batch_start:limit])
            Y = load_img(mask_dir, mask_list[batch_start:limit])

            yield (X,Y) #a tuple with two numpy arrays with batch_size samples

            batch_start += batch_size
            batch_end += batch_size

#Test the generator (To check that image and masks come from same patients)
from matplotlib import pyplot as plt
import random

train_img_dir = "/path of training data"
train_mask_dir = "/path of training mask data"

train_img_list=os.listdir(train_img_dir)
train_mask_list = os.listdir(train_mask_dir)

batch_size = 16

train_img_datagen = imageLoader(train_img_dir, train_img_list,
                                train_mask_dir, train_mask_list, batch_size)

#Verify generator.... In python 3 next() is renamed as __next__()
img, msk = train_img_datagen.__next__()

img_num = random.randint(0,img.shape[0]-1)
test_img=img[img_num]
test_mask=msk[img_num]
test_mask=np.argmax(test_mask, axis=3)

n_slice=random.randint(0, test_mask.shape[2])
plt.figure(figsize=(12, 8))

plt.subplot(231)
plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')  # Use 'viridis' colormap
plt.title('Image flair')

plt.subplot(232)
plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')  # Use 'plasma' colormap
plt.title('Image t1ce')

plt.subplot(233)
plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')  # Use 'inferno' colormap
plt.title('Image t2')

plt.subplot(234)
plt.imshow(test_img[:,:,n_slice, 3], cmap='gray')  # Use 'magma' colormap
plt.title('Image t1')

plt.subplot(235)
plt.imshow(test_mask[:,:,n_slice], cmap='gray')  # Use 'jet' colormap for the mask
plt.title('Mask')

plt.show()

"""## **Loading Data from Image loader in the form of batches**"""

#Defining the image generators for training and validation

train_img_dir = "train_image/"
train_mask_dir = "train_masks/"

val_img_dir = "valid_images/"
val_mask_dir = "valid_masks/"

train_img_list=os.listdir(train_img_dir)
train_mask_list = os.listdir(train_mask_dir)

val_img_list=os.listdir(val_img_dir)
val_mask_list = os.listdir(val_mask_dir)

batch_size = 4

train_img_datagen = imageLoader(train_img_dir, train_img_list,
                                train_mask_dir, train_mask_list, batch_size)

val_img_datagen = imageLoader(val_img_dir, val_img_list,
                                val_mask_dir, val_mask_list, batch_size)

"""## **Defining Loss Functions and Dice Coefficents**"""

def _dice_hard_coe(target, output, smooth=1e-5):
    output = tf.cast(output, dtype=tf.float32)
    target = tf.cast(target, dtype=tf.float32)

    inse = tf.reduce_sum(tf.multiply(output, target))
    l = tf.reduce_sum(output)
    r = tf.reduce_sum(target)
    hard_dice = (2. * inse + smooth) / (l + r + smooth)
    return tf.reduce_mean(hard_dice)

def brats_wt(y_true, y_pred):
    # whole tumor
    y_true = tf.argmax(y_true, axis=-1)
    y_pred = tf.argmax(y_pred, axis=-1)
    gt_wt = tf.cast(tf.identity(y_true), tf.int32)
    gt_wt = tf.where(tf.equal(2, gt_wt), 1 * tf.ones_like(gt_wt), gt_wt)  # ground_truth_wt[ground_truth_wt == 2] = 1
    gt_wt = tf.where(tf.equal(3, gt_wt), 1 * tf.ones_like(gt_wt), gt_wt)  # ground_truth_wt[ground_truth_wt == 3] = 1
    pd_wt = tf.cast(tf.round(tf.identity(y_pred)), tf.int32)
    pd_wt = tf.where(tf.equal(2, pd_wt), 1 * tf.ones_like(pd_wt), pd_wt)  # predictions_wt[predictions_wt == 2] = 1
    pd_wt = tf.where(tf.equal(3, pd_wt), 1 * tf.ones_like(pd_wt), pd_wt)  # predictions_wt[predictions_wt == 3] = 1
    return _dice_hard_coe(gt_wt, pd_wt)


def brats_tc(y_true, y_pred):
    # tumor core
    y_true = tf.argmax(y_true, axis=-1)
    y_pred = tf.argmax(y_pred, axis=-1)
    gt_tc = tf.cast(tf.identity(y_true), tf.int32)
    gt_tc = tf.where(tf.equal(2, gt_tc), 0 * tf.ones_like(gt_tc), gt_tc)  # ground_truth_tc[ground_truth_tc == 2] = 0
    gt_tc = tf.where(tf.equal(3, gt_tc), 1 * tf.ones_like(gt_tc), gt_tc)  # ground_truth_tc[ground_truth_tc == 3] = 1
    pd_tc = tf.cast(tf.round(tf.identity(y_pred)), tf.int32)
    pd_tc = tf.where(tf.equal(2, pd_tc), 0 * tf.ones_like(pd_tc), pd_tc)  # predictions_tc[predictions_tc == 2] = 0
    pd_tc = tf.where(tf.equal(3, pd_tc), 1 * tf.ones_like(pd_tc), pd_tc)  # predictions_tc[predictions_tc == 3] = 1
    return _dice_hard_coe(gt_tc, pd_tc)


def brats_et(y_true, y_pred):
    # enhancing tumor
    y_true = tf.argmax(y_true, axis=-1)
    y_pred = tf.argmax(y_pred, axis=-1)
    gt_et = tf.cast(tf.identity(y_true), tf.int32)
    gt_et = tf.where(tf.equal(1, gt_et), 0 * tf.ones_like(gt_et), gt_et)  # ground_truth_et[ground_truth_et == 1] = 0
    gt_et = tf.where(tf.equal(2, gt_et), 0 * tf.ones_like(gt_et), gt_et)  # ground_truth_et[ground_truth_et == 2] = 0
    gt_et = tf.where(tf.equal(3, gt_et), 1 * tf.ones_like(gt_et), gt_et)  # ground_truth_et[ground_truth_et == 3] = 1
    pd_et = tf.cast(tf.round(tf.identity(y_pred)), tf.int32)
    pd_et = tf.where(tf.equal(1, pd_et), 0 * tf.ones_like(pd_et), pd_et)  # predictions_et[predictions_et == 1] = 0
    pd_et = tf.where(tf.equal(2, pd_et), 0 * tf.ones_like(pd_et), pd_et)  # predictions_et[predictions_et == 2] = 0
    pd_et = tf.where(tf.equal(3, pd_et), 1 * tf.ones_like(pd_et), pd_et)  # predictions_et[predictions_et == 3] = 1
    return _dice_hard_coe(gt_et, pd_et)

def dice_coefficient(y_true, y_pred, epsilon=0.00001):
    """
    Dice = (2*|X & Y|)/ (|X|+ |Y|)
         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))
    ref: https://arxiv.org/pdf/1606.04797v1.pdf

    """
    axis = (0,1,2,3)
    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon
    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon
    return K.mean((dice_numerator)/(dice_denominator))

def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3),
                   epsilon=0.00001):
    """
    Compute mean soft dice loss over all abnormality classes.

    Args:
        y_true (Tensorflow tensor): tensor of ground truth values for all classes.
                                    shape: (num_classes, x_dim, y_dim, z_dim)
        y_pred (Tensorflow tensor): tensor of soft predictions for all classes.
                                    shape: (num_classes, x_dim, y_dim, z_dim)
        axis (tuple): spatial axes to sum over when computing numerator and
                      denominator in formula for dice loss.
                      Hint: pass this as the 'axis' argument to the K.sum
                            and K.mean functions.
        epsilon (float): small constant added to numerator and denominator to
                        avoid divide by 0 errors.
    Returns:
        dice_loss (float): computed value of dice loss.
    """

    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon
    dice_denominator = K.sum(y_true**2, axis=axis) + K.sum(y_pred**2, axis=axis) + epsilon
    dice_loss = 1 - K.mean((dice_numerator)/(dice_denominator))

    return dice_loss

# Computing Sensitivity
def sensitivity(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    return true_positives / (possible_positives + K.epsilon())


# Computing Specificity
def specificity(y_true, y_pred):
    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))
    return true_negatives / (possible_negatives + K.epsilon())

def sensitivity_wt(true_positive, false_negative):
    """
    Calculate sensitivity (true positive rate) given the true positive and false negative counts.
    """
    return true_positive / (true_positive + false_negative)


def specificity_wt(true_negative, false_positive):
    """
    Calculate specificity (true negative rate) given the true negative and false positive counts.
    """
    return true_negative / (true_negative + false_positive)

def sensitivity_tc(true_positive, false_negative):
    """
    Calculate sensitivity (true positive rate) given the true positive and false negative counts.
    """
    return true_positive / (true_positive + false_negative)


def specificity_tc(true_negative, false_positive):
    """
    Calculate specificity (true negative rate) given the true negative and false positive counts.
    """
    return true_negative / (true_negative + false_positive)

def sensitivity_et(true_positive, false_negative):
    """
    Calculate sensitivity (true positive rate) given the true positive and false negative counts.
    """
    return true_positive / (true_positive + false_negative)


def specificity_et(true_negative, false_positive):
    """
    Calculate specificity (true negative rate) given the true negative and false positive counts.
    """
    return true_negative / (true_negative + false_positive)

"""## **Model: 3D Deep Residual U-Net MOdel**"""

# Convolutional Blocks

def conv_block(input_mat,num_filters,kernel_size,batch_norm):
  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(input_mat)
  X = BatchNormalization()(X)
  X = Activation('relu')(X)

  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(X)
  X = BatchNormalization()(X)
  X = Activation('relu')(X)

  return X

# Residual Convolutional Blocks

def res_conv_block(x, filter_size, size, batch_norm=True):

    dropout = 0.2

    conv = layers.Conv3D(size, (filter_size, filter_size,filter_size), padding='same')(x)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=4)(conv)
    conv = layers.Activation('relu')(conv)

    conv = layers.Conv3D(size, (filter_size, filter_size,filter_size), padding='same')(conv)
    if batch_norm is True:
        conv = layers.BatchNormalization(axis=4)(conv)
    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut
    if dropout > 0:
        conv = layers.Dropout(dropout)(conv)

    shortcut = layers.Conv3D(size, kernel_size=(1,1, 1), padding='same')(x)
    if batch_norm is True:
        shortcut = layers.BatchNormalization(axis=4)(shortcut)

    res_path = layers.add([shortcut, conv])
    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)
    return res_path

# Model Architectural Design

def Residual_Unet_3d(input_img, n_filters = 16, dropout = 0.1, batch_norm = True):
## Downsaming - Encoder of U-Net with Residual Blocks
  c1 = res_conv_block(input_img,n_filters,3,batch_norm)
  p1 = MaxPooling3D(pool_size=(2, 2, 2), strides=2)(c1)
  p1 = Dropout(dropout)(p1)

  c2 = res_conv_block(p1,n_filters*2,3,batch_norm);
  p2 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c2)
  p2 = Dropout(dropout)(p2)

  c3 = res_conv_block(p2,n_filters*4,3,batch_norm);
  p3 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c3)
  p3 = Dropout(dropout)(p3)

  c4 = res_conv_block(p3,n_filters*8,3,batch_norm);
  p4 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c4)
  p4 = Dropout(dropout)(p4)
## Bottleneck layer
  c5 = conv_block(p4,n_filters*16,3,batch_norm);
## UPsaming - Decoder of U-Net with Conv Blocks
  u6 = Conv3DTranspose(n_filters*8, (3,3,3), strides=(2, 2, 2), padding='same')(c5);
  u6 = concatenate([u6,c4]);
  c6 = conv_block(u6,n_filters*8,3,batch_norm)
  c6 = Dropout(dropout)(c6)

  u7 = Conv3DTranspose(n_filters*4,(3,3,3),strides = (2,2,2) , padding= 'same')(c6);
  u7 = concatenate([u7,c3]);
  c7 = conv_block(u7,n_filters*4,3,batch_norm)
  c7 = Dropout(dropout)(c7)

  u8 = Conv3DTranspose(n_filters*2,(3,3,3),strides = (2,2,2) , padding='same')(c7);
  u8 = concatenate([u8,c2]);
  c8 = conv_block(u8,n_filters*2,3,batch_norm)
  c8 = Dropout(dropout)(c8)

  u9 = Conv3DTranspose(n_filters,(3,3,3),strides = (2,2,2) , padding='same')(c8);
  u9 = concatenate([u9,c1]);
  c9 = conv_block(u9,n_filters,3,batch_norm)

  outputs = Conv3D(4,(1, 1,1), activation='softmax')(c9)

  model = Model(inputs=input_img, outputs=outputs)

  return model

"""### **Building the model**"""

input_img = Input((128,128,128,4))
res_unet = Residual_Unet_3d(input_img,16,0.1,True)
print(res_unet.input_shape)
print(res_unet.output_shape)

"""### **Model Compiling**"""

metrics = [dice_coefficient, brats_wt , brats_tc ,brats_et,sensitivity,specificity]
learning_rate = 0.0005
optimizer = tf.keras.optimizers.Adam(learning_rate)

res_unet.compile(optimizer = optimizer, loss=soft_dice_loss, metrics=metrics)
res_unet.summary()

#Fit the model
steps_per_epoch = len(train_img_list)//batch_size
val_steps_per_epoch = len(val_img_list)//batch_size

"""## **Model Training: Fitting the model over train and validation data**"""

checkpoint_path = '/Final_Model_Results'
callbacks = []
callbacks.append(ModelCheckpoint(checkpoint_path + '/dResUnet_epoch-{epoch}.h5'))

history=res_unet.fit(train_img_datagen,
          steps_per_epoch=steps_per_epoch,
          epochs=100,
          validation_data=val_img_datagen,
          validation_steps=val_steps_per_epoch,
          callbacks=[callbacks], verbose=1
          )